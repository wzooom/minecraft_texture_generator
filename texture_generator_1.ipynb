{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1S26lE1_XmXWcsiMVo_v0winoWPSnsrzD",
      "authorship_tag": "ABX9TyN9PecSRlMr0FEOzz55keVx",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/wzooom/minecraft_texture_generator/blob/main/texture_generator_1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Reshape\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split\n",
        "import os\n",
        "import urllib.request\n",
        "import tarfile\n",
        "from PIL import Image\n",
        "\n",
        "def preprocess_description(description):\n",
        "    \"\"\"Convert textual description into a numerical feature vector.\"\"\"\n",
        "    # Placeholder: Use pretrained embeddings like Word2Vec, GloVe, or BERT in a real implementation.\n",
        "    return np.random.rand(128)\n",
        "\n",
        "def build_texture_model(input_dim):\n",
        "    \"\"\"Build a neural network to generate 16x16 textures.\"\"\"\n",
        "    model = Sequential([\n",
        "        Dense(256, activation='relu', input_dim=input_dim),\n",
        "        Dense(512, activation='relu'),\n",
        "        Dense(16 * 16 * 3, activation='sigmoid'),  # Output a 16x16 RGB texture\n",
        "        Reshape((16, 16, 3))\n",
        "    ])\n",
        "    model.compile(optimizer=Adam(learning_rate=0.001), loss='mse')\n",
        "    return model\n",
        "\n",
        "def download_and_prepare_dtd():\n",
        "    \"\"\"Download and prepare the Describable Textures Dataset (DTD).\"\"\"\n",
        "    url = \"https://www.robots.ox.ac.uk/~vgg/data/dtd/download/dtd-r1.0.1.tar.gz\"\n",
        "    dataset_dir = \"dtd_dataset\"\n",
        "    tar_file = \"dtd.tar.gz\"\n",
        "\n",
        "    # Download DTD if not already downloaded\n",
        "    if not os.path.exists(tar_file):\n",
        "        print(\"Downloading DTD...\")\n",
        "        urllib.request.urlretrieve(url, tar_file)\n",
        "\n",
        "    # Extract DTD if not already extracted\n",
        "    if not os.path.exists(dataset_dir):\n",
        "        print(\"Extracting DTD...\")\n",
        "        with tarfile.open(tar_file, 'r:gz') as tar_ref:\n",
        "            tar_ref.extractall(path=\".\")\n",
        "\n",
        "    # Load texture paths and descriptions\n",
        "    texture_dir = os.path.join(\"dtd\", \"images\")\n",
        "    categories = os.listdir(texture_dir)\n",
        "    descriptions, texture_paths = [], []\n",
        "\n",
        "    for category in categories:\n",
        "        category_dir = os.path.join(texture_dir, category)\n",
        "        if os.path.isdir(category_dir):\n",
        "            for file_name in os.listdir(category_dir):\n",
        "                if file_name.endswith(('.jpg', '.png', '.jpeg')):\n",
        "                    texture_paths.append(os.path.join(category_dir, file_name))\n",
        "                    descriptions.append(f\"A texture that is {category}.\")\n",
        "\n",
        "    return descriptions, texture_paths\n",
        "\n",
        "def combine_datasets(dtd_features, dtd_textures, png_features, png_textures):\n",
        "    \"\"\"Combine the DTD and PNG datasets.\"\"\"\n",
        "    combined_features = np.concatenate((dtd_features, png_features), axis=0)\n",
        "    combined_textures = np.concatenate((dtd_textures, png_textures), axis=0)\n",
        "    return combined_features, combined_textures\n",
        "\n",
        "\n",
        "def load_dtd_dataset():\n",
        "    \"\"\"Load DTD dataset and preprocess it.\"\"\"\n",
        "    descriptions, texture_paths = download_and_prepare_dtd()\n",
        "    features = np.array([preprocess_description(desc) for desc in descriptions])\n",
        "\n",
        "    textures = []\n",
        "    for path in texture_paths:\n",
        "        img = Image.open(path).convert('RGB').resize((16, 16))  # Resize to 16x16\n",
        "        textures.append(np.array(img) / 255.0)  # Normalize to [0, 1]\n",
        "\n",
        "    textures = np.array(textures)\n",
        "    return features, textures\n",
        "\n",
        "def split_dataset(features, textures):\n",
        "    \"\"\"Split dataset into training, validation, and testing sets.\"\"\"\n",
        "    X_train, X_temp, y_train, y_temp = train_test_split(features, textures, test_size=0.4, random_state=42)\n",
        "    X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42)\n",
        "    return X_train, X_val, X_test, y_train, y_val, y_test\n",
        "\n",
        "# Load DTD dataset\n",
        "features, textures = load_dtd_dataset()\n",
        "\n",
        "# Split the dataset\n",
        "X_train, X_val, X_test, y_train, y_val, y_test = split_dataset(features, textures)\n",
        "\n",
        "# Build the model\n",
        "input_dim = 128\n",
        "model = build_texture_model(input_dim)\n",
        "\n",
        "# Train the model\n",
        "model.fit(X_train, y_train, validation_data=(X_val, y_val), epochs=50, batch_size=32)\n",
        "\n",
        "# Evaluate the model\n",
        "loss = model.evaluate(X_test, y_test)\n",
        "print(f\"Test Loss: {loss}\")\n",
        "\n",
        "def generate_texture(description):\n",
        "    \"\"\"Generate a texture based on a description.\"\"\"\n",
        "    processed_description = preprocess_description(description)\n",
        "    processed_description = np.expand_dims(processed_description, axis=0)  # Add batch dimension\n",
        "    texture = model.predict(processed_description)[0]\n",
        "    return texture\n",
        "\n",
        "# Example usage\n",
        "description = \"A grassy texture with hints of dirt.\"\n",
        "generated_texture = generate_texture(description)\n",
        "\n",
        "# Display the generated texture\n",
        "plt.imshow(generated_texture)\n",
        "plt.title(description)\n",
        "plt.axis('off')\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "9YNmdZfW2mu3",
        "outputId": "ce2d2a5b-f5cd-4b04-f79d-0de0111d17ff"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting DTD...\n",
            "Epoch 1/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m106/106\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 20ms/step - loss: 0.0497 - val_loss: 0.0499\n",
            "Epoch 2/50\n",
            "\u001b[1m106/106\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.0498 - val_loss: 0.0498\n",
            "Epoch 3/50\n",
            "\u001b[1m106/106\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.0491 - val_loss: 0.0501\n",
            "Epoch 4/50\n",
            "\u001b[1m106/106\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0489 - val_loss: 0.0500\n",
            "Epoch 5/50\n",
            "\u001b[1m106/106\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.0486 - val_loss: 0.0504\n",
            "Epoch 6/50\n",
            "\u001b[1m106/106\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.0488 - val_loss: 0.0506\n",
            "Epoch 7/50\n",
            "\u001b[1m106/106\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.0476 - val_loss: 0.0513\n",
            "Epoch 8/50\n",
            "\u001b[1m106/106\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.0482 - val_loss: 0.0503\n",
            "Epoch 9/50\n",
            "\u001b[1m106/106\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.0478 - val_loss: 0.0521\n",
            "Epoch 10/50\n",
            "\u001b[1m106/106\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 16ms/step - loss: 0.0466 - val_loss: 0.0517\n",
            "Epoch 11/50\n",
            "\u001b[1m106/106\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 18ms/step - loss: 0.0449 - val_loss: 0.0514\n",
            "Epoch 12/50\n",
            "\u001b[1m106/106\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - loss: 0.0430 - val_loss: 0.0522\n",
            "Epoch 13/50\n",
            "\u001b[1m106/106\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.0424 - val_loss: 0.0542\n",
            "Epoch 14/50\n",
            "\u001b[1m106/106\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.0398 - val_loss: 0.0571\n",
            "Epoch 15/50\n",
            "\u001b[1m106/106\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.0398 - val_loss: 0.0573\n",
            "Epoch 16/50\n",
            "\u001b[1m106/106\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.0372 - val_loss: 0.0581\n",
            "Epoch 17/50\n",
            "\u001b[1m106/106\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.0357 - val_loss: 0.0631\n",
            "Epoch 18/50\n",
            "\u001b[1m106/106\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.0341 - val_loss: 0.0595\n",
            "Epoch 19/50\n",
            "\u001b[1m106/106\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.0334 - val_loss: 0.0613\n",
            "Epoch 20/50\n",
            "\u001b[1m106/106\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 16ms/step - loss: 0.0315 - val_loss: 0.0606\n",
            "Epoch 21/50\n",
            "\u001b[1m106/106\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 17ms/step - loss: 0.0306 - val_loss: 0.0616\n",
            "Epoch 22/50\n",
            "\u001b[1m106/106\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - loss: 0.0286 - val_loss: 0.0621\n",
            "Epoch 23/50\n",
            "\u001b[1m106/106\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.0286 - val_loss: 0.0641\n",
            "Epoch 24/50\n",
            "\u001b[1m106/106\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.0271 - val_loss: 0.0642\n",
            "Epoch 25/50\n",
            "\u001b[1m106/106\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.0265 - val_loss: 0.0628\n",
            "Epoch 26/50\n",
            "\u001b[1m106/106\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.0251 - val_loss: 0.0644\n",
            "Epoch 27/50\n",
            "\u001b[1m106/106\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.0243 - val_loss: 0.0651\n",
            "Epoch 28/50\n",
            "\u001b[1m106/106\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 17ms/step - loss: 0.0236 - val_loss: 0.0651\n",
            "Epoch 29/50\n",
            "\u001b[1m106/106\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 18ms/step - loss: 0.0234 - val_loss: 0.0655\n",
            "Epoch 30/50\n",
            "\u001b[1m106/106\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 21ms/step - loss: 0.0224 - val_loss: 0.0663\n",
            "Epoch 31/50\n",
            "\u001b[1m106/106\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 18ms/step - loss: 0.0217 - val_loss: 0.0676\n",
            "Epoch 32/50\n",
            "\u001b[1m106/106\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - loss: 0.0210 - val_loss: 0.0668\n",
            "Epoch 33/50\n",
            "\u001b[1m106/106\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.0203 - val_loss: 0.0678\n",
            "Epoch 34/50\n",
            "\u001b[1m106/106\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.0199 - val_loss: 0.0674\n",
            "Epoch 35/50\n",
            "\u001b[1m106/106\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.0201 - val_loss: 0.0686\n",
            "Epoch 36/50\n",
            "\u001b[1m106/106\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.0191 - val_loss: 0.0683\n",
            "Epoch 37/50\n",
            "\u001b[1m106/106\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.0190 - val_loss: 0.0674\n",
            "Epoch 38/50\n",
            "\u001b[1m106/106\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.0185 - val_loss: 0.0686\n",
            "Epoch 39/50\n",
            "\u001b[1m106/106\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0185 - val_loss: 0.0697\n",
            "Epoch 40/50\n",
            "\u001b[1m106/106\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 16ms/step - loss: 0.0177 - val_loss: 0.0698\n",
            "Epoch 41/50\n",
            "\u001b[1m106/106\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 18ms/step - loss: 0.0175 - val_loss: 0.0709\n",
            "Epoch 42/50\n",
            "\u001b[1m106/106\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.0170 - val_loss: 0.0701\n",
            "Epoch 43/50\n",
            "\u001b[1m106/106\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.0174 - val_loss: 0.0705\n",
            "Epoch 44/50\n",
            "\u001b[1m106/106\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.0170 - val_loss: 0.0703\n",
            "Epoch 45/50\n",
            "\u001b[1m106/106\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.0163 - val_loss: 0.0719\n",
            "Epoch 46/50\n",
            "\u001b[1m106/106\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.0166 - val_loss: 0.0716\n",
            "Epoch 47/50\n",
            "\u001b[1m106/106\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 0.0158 - val_loss: 0.0718\n",
            "Epoch 48/50\n",
            "\u001b[1m106/106\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.0160 - val_loss: 0.0721\n",
            "Epoch 49/50\n",
            "\u001b[1m106/106\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.0153 - val_loss: 0.0719\n",
            "Epoch 50/50\n",
            "\u001b[1m106/106\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 16ms/step - loss: 0.0157 - val_loss: 0.0731\n",
            "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0743\n",
            "Test Loss: 0.07301532477140427\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 92ms/step\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    }
  ]
}